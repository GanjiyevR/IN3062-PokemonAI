{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd532f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import save_and_load\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#prepares the dataframe passed as a parameter and returns an X and y with y being cast to categorial\n",
    "def prepare_data(dataframe):\n",
    "    #collect the columns names for non-target features\n",
    "    result = []\n",
    "    for x in dataframe.columns:\n",
    "        if (x == 'attack') or (x == 'defense') or (x == 'speed') or (x == 'sp_defense') or (x == 'sp_attack') or (x == 'hp'):\n",
    "            result.append(x)\n",
    "        elif False and ((x == 'weight_kg') or (x == 'height_m')):\n",
    "            #added this sepperate if statement to have to option to exlude weight and height from being considered\n",
    "            result.append(x)\n",
    "\n",
    "    #get data (often called X) and target (often calle y) and display its shape\n",
    "    X = dataframe[result].values\n",
    "    y = dataframe['is_legendary'].values\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    y = keras.utils.to_categorical(dataframe['is_legendary'].to_numpy())\n",
    "    return X, y\n",
    "\n",
    "# output prediciton accuracy of a model on a given X and compare it to the given y of correct values, \n",
    "# put True or False as the last parameter to determine if additonal information on predictions should be displayed\n",
    "def show_prediction(model, X, y, show):\n",
    "    # make a prediction using all the data\n",
    "    pred = model.predict(X)\n",
    "    # show the shape if the inputs\n",
    "    if show:\n",
    "        print(pred.shape)\n",
    "        print(y.shape)\n",
    "        print(\"\\n Predictions: \\n\")\n",
    "        print(np.round(pred[0:20], 3))\n",
    "        print(\"\\n Actual values: \\n\")\n",
    "        print(y[0:20])\n",
    "    pred_val = np.argmax(pred,axis=1)\n",
    "    y_compare = np.argmax(y,axis=1)\n",
    "    print(\"\\n Predictions: \\n\")\n",
    "    print(pred_val[0:20])\n",
    "    print(\"\\n Actual values: \\n\")\n",
    "    print(y_compare[0:20])\n",
    "\n",
    "    #print the accuracy of the model\n",
    "    score = metrics.accuracy_score(y_compare, pred_val)\n",
    "    print(\"Accuracy score: {}\".format(score))\n",
    "    return pred, pred_val, y_compare\n",
    "\n",
    "path = \".\"  #absolute or relative path to the folder containing the file. \n",
    "            #\".\" for current folder\n",
    "\n",
    "#import the data from the dataset\n",
    "filename_read = os.path.join(path, \"pokemon.csv\")\n",
    "df = pd.read_csv(filename_read)\n",
    "\n",
    "#show the order of the first few entries\n",
    "print(df[0:5]['is_legendary'])\n",
    "#shuffle them (with randon seed 42)\n",
    "np.random.seed(42)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "#check if they have been shuffeled\n",
    "print(df[0:5]['is_legendary'])\n",
    "\n",
    "#copy the dataframe to encode it without changing the initial dataframe\n",
    "encodeddf = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingdf = encodeddf[0:721]\n",
    "holdoutdf = encodeddf[722:890]\n",
    "\n",
    "print(\"Total Non-/Legendary Counts: \\n\" + str(encodeddf['is_legendary'].value_counts()) + \"\\n\")\n",
    "print(\"Training Non-/Legendary Counts: \\n\" + str(trainingdf['is_legendary'].value_counts()) + \"\\n\")\n",
    "print(\"Holdout Non-/Legendary Counts: \\n\" + str(holdoutdf['is_legendary'].value_counts()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data(trainingdf)\n",
    "\n",
    "# make a sequential model and train it using KFold splits\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=X.shape[1], activation='relu'))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', metrics = keras.metrics.AUC(), optimizer='adam')\n",
    "\n",
    "kf = KFold(6)\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    model.fit(X_train,y_train,verbose=0,epochs=100)\n",
    "    pred = model.predict(X_test)\n",
    "    pred = np.argmax(pred,axis=1)\n",
    "    y_compare = np.argmax(y_test,axis=1) \n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "# save the model\n",
    "save_and_load.save_model(model, path, \"seqKFoldLegendary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32103a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data(trainingdf)\n",
    "# Create and fit a nearest-neighbor classifier\n",
    "# Using the data and target split from the previous section called X and y\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X, y) \n",
    "\n",
    "# Create and fit a random forest classifier\n",
    "# Using the data and target split from the previous section called X and y\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Instantiate the model with 10 trees and entropy as splitting criteria\n",
    "Random_Forest_model = RandomForestClassifier(n_estimators=50,criterion=\"entropy\")\n",
    "#Train the model\n",
    "Random_Forest_model.fit(X, y)\n",
    "\n",
    "\n",
    "#training and test set\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_test, y_test = prepare_data(holdoutdf)\n",
    "\n",
    "\n",
    "#knn\n",
    "print(\"___KNN___\")\n",
    "print(\"Predictions form the classifier:\")\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred[:5])\n",
    "print(\"Target values:\")\n",
    "print(y_test[0:5])\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('The accuracy is: ',accuracy*100,'%')\n",
    "#random forest\n",
    "print(\"___RANDOM FOREST___\")\n",
    "print(\"Predictions form the classifier:\")\n",
    "y_pred = Random_Forest_model.predict(X_test)\n",
    "print(y_pred[:5])\n",
    "print(\"Target values:\")\n",
    "print(y_test[:5])\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('The accuracy is: ',accuracy*100,'%')\n",
    "\n",
    "#investigates the accuracy over a range of estimators plotting the results\n",
    "accuracy_data = []\n",
    "nums = []\n",
    "for i in range(1,120):\n",
    "    rf_model = RandomForestClassifier(n_estimators=i,criterion=\"entropy\")\n",
    "    rf_model.fit(X, y)\n",
    "    y_model = rf_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_model, y_test)\n",
    "    accuracy_data.append(accuracy)\n",
    "    nums.append(i)\n",
    "    \n",
    "print(accuracy_data)\n",
    "plt.plot(nums,accuracy_data)\n",
    "plt.xlabel(\"Number of Trees (n_estimators)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cdeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA to visualize possible relationships that exists in the data\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#prepare X and y for all the data\n",
    "X, y = prepare_data(encodeddf)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_std = sc.transform(X)\n",
    "\n",
    "pca = PCA(2)  # project from 8 to 2 dimensions\n",
    "projected = pca.fit_transform(X_std)\n",
    "print(X_std.shape)\n",
    "print(projected.shape)\n",
    "#display the highhest explained variance and ratio for both classes\n",
    "print(\"Explained Variance: \" + str(pca.explained_variance_))\n",
    "print(\"Explained Variance Ratio: \" + str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=np.argmax(y,axis=1), edgecolor='none', alpha=0.9,\n",
    "            cmap=plt.cm.get_cmap('tab10', 2))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();\n",
    "plt.xlim(-4, 7.5)\n",
    "plt.ylim(-4, 8)\n",
    "plt.show()\n",
    "    \n",
    "for count in range(0, len(encodeddf['is_legendary'].unique())):\n",
    "    print(\"is legendary: \" + str(count))\n",
    "    #prepare X and y for each indivual type\n",
    "    X, y = prepare_data(encodeddf[encodeddf['is_legendary'] == count])\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X)\n",
    "    X_std = sc.transform(X)\n",
    "\n",
    "    pca = PCA(2)  # project from 8 to 2 dimensions\n",
    "    projected = pca.fit_transform(X_std)\n",
    "    print(X_std.shape)\n",
    "    print(projected.shape)\n",
    "    #display the highhest explained variance and ratio for the classes individualy\n",
    "    print(\"Explained Variance: \" + str(pca.explained_variance_))\n",
    "    print(\"Explained Variance Ratio: \" + str(pca.explained_variance_ratio_))\n",
    "\n",
    "    plt.scatter(projected[:, 0], projected[:, 1],\n",
    "                c=np.argmax(y,axis=1), edgecolor='none', alpha=0.9,\n",
    "                cmap=plt.cm.get_cmap('tab10', 2))\n",
    "    plt.xlabel('component 1')\n",
    "    plt.ylabel('component 2')\n",
    "    plt.colorbar();\n",
    "    plt.xlim(-4, 7.5)\n",
    "    plt.ylim(-4, 8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the holdout set with the trained model saved in this folder \n",
    "# (loading a save is currently redundant as the shuffling is done without a set random seed)\n",
    "X_test, y_test = prepare_data(holdoutdf)\n",
    "\n",
    "model = save_and_load.model_loader(path, \"seqKFoldLegendary\")\n",
    "\n",
    "pred, pred_val, y_compare = show_prediction(model, X_test, y_test, False)\n",
    "\n",
    "#print the values from the list\n",
    "print(holdoutdf[\"Name\"][:20])\n",
    "print(pred[20])\n",
    "\n",
    "#plot a confusion matrix for the predicitons\n",
    "cm = confusion_matrix(y_compare, pred_val)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
